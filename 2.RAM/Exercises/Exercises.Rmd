---
title: "Exercises"
author: "Pedro Ojeda, Birgitte Bryds√∂, Mirko Myllykoski, Lars Viklund"
date: "May 27th, 2020"
output: html_document
---


## Problem 1.
Using the functions sumcol() and colSums() from the Profiling section, obtain a memory profiling summary using Rprof

## Problem 2.
Using the setup, from slide 17 of the lecture for the large array *bm*, compute the mean and standard deviation of each column for a matrix with a size $10^7 \times 3$ and using chunks of $10^6$.

## Problem 3. 
The following R code uses a cutoff of 0.05 to assing the value **NA** to the vector elements:

```{r}
x <- runif(1e+06)
for (i in 1:length(x)) {
  if (x[i] < 0.05) {
    x[i] <- NA
  }
}
```

below is the vectorized counterpart:

```{r}
x <- runif(1e+06)
x[which(x < 0.05)] <- NA 
```

compare the execution times of both functions using vector sizes of 1e+06, 1e+07, and 1e+08. Which function showed the best performance?

Use *gcinfo* to analyze the memory used by both codes (plain loop and the vectorized one) as follows: 

```{r eval=FALSE}
x <- runif(1e+08)
#Plain loop
gcinfo(TRUE)
  for (i in 1:length(x)) {
    if (x[i] < 0.05) {
      x[i] <- NA
    }
  }
gcinfo(FALSE)
```

```{r eval=FALSE}
x <- runif(1e+08)
#Vectorized code
gcinfo(TRUE)
  x[which(x < 0.05)] <- NA 
gcinfo(FALSE)
```

which code uses more memory? Based on this result, when would it be more appropriate to use the plain loop and when the vectorized code? **Note: in order to run the codes for the plain loop and the vectorized code, one needs to start with a fresh R session (Ctrl+Shift+F10)**